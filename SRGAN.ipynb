{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Single Image Super-Resolution Using SRGAN\n",
    "    \n",
    "All images resized to 128x128 to represent HR and 32x32 to represent LR.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Conv2D, PReLU,BatchNormalization, Flatten\n",
    "from keras.layers import UpSampling2D, LeakyReLU, Dense, Input, add\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "\n",
    "#Define blocks to build the generator\n",
    "def res_block(ip):\n",
    "    \n",
    "    res_model = Conv2D(64, (3,3), padding = \"same\")(ip)\n",
    "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
    "    res_model = PReLU(shared_axes = [1,2])(res_model)\n",
    "    \n",
    "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
    "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
    "    \n",
    "    return add([ip,res_model])\n",
    "\n",
    "def upscale_block(ip):\n",
    "    \n",
    "    up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
    "    up_model = UpSampling2D( size = 2 )(up_model)\n",
    "    up_model = PReLU(shared_axes=[1,2])(up_model)\n",
    "    \n",
    "    return up_model\n",
    "\n",
    "#Generator model\n",
    "def create_gen(gen_ip, num_res_block):\n",
    "    layers = Conv2D(64, (9,9), padding=\"same\")(gen_ip)\n",
    "    layers = PReLU(shared_axes=[1,2])(layers)\n",
    "\n",
    "    temp = layers\n",
    "\n",
    "    for i in range(num_res_block):\n",
    "        layers = res_block(layers)\n",
    "\n",
    "    layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
    "    layers = BatchNormalization(momentum=0.5)(layers)\n",
    "    layers = add([layers,temp])\n",
    "\n",
    "    layers = upscale_block(layers)\n",
    "    layers = upscale_block(layers)\n",
    "\n",
    "    op = Conv2D(3, (9,9), padding=\"same\")(layers)\n",
    "\n",
    "    return Model(inputs=gen_ip, outputs=op)\n",
    "\n",
    "#Discriminator block that will be used to construct the discriminator\n",
    "def discriminator_block(ip, filters, strides=1, bn=True):\n",
    "    \n",
    "    disc_model = Conv2D(filters, (3,3), strides = strides, padding=\"same\")(ip)\n",
    "    \n",
    "    if bn:\n",
    "        disc_model = BatchNormalization( momentum=0.8 )(disc_model)\n",
    "    \n",
    "    disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
    "    \n",
    "    return disc_model\n",
    "\n",
    "\n",
    "#Discriminator model\n",
    "def create_disc(disc_ip):\n",
    "\n",
    "    df = 64\n",
    "    \n",
    "    d1 = discriminator_block(disc_ip, df, bn=False)\n",
    "    d2 = discriminator_block(d1, df, strides=2)\n",
    "    d3 = discriminator_block(d2, df*2)\n",
    "    d4 = discriminator_block(d3, df*2, strides=2)\n",
    "    d5 = discriminator_block(d4, df*4)\n",
    "    d6 = discriminator_block(d5, df*4, strides=2)\n",
    "    d7 = discriminator_block(d6, df*8)\n",
    "    d8 = discriminator_block(d7, df*8, strides=2)\n",
    "    \n",
    "    d8_5 = Flatten()(d8)\n",
    "    d9 = Dense(df*16)(d8_5)\n",
    "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
    "    validity = Dense(1, activation='sigmoid')(d10)\n",
    "\n",
    "    return Model(disc_ip, validity)\n",
    "\n",
    "#VGG19 \n",
    "from keras.applications import VGG19\n",
    "\n",
    "def build_vgg(hr_shape):\n",
    "    \n",
    "    vgg = VGG19(weights=\"imagenet\",include_top=False, input_shape=hr_shape)\n",
    "    \n",
    "    return Model(inputs=vgg.inputs, outputs=vgg.layers[10].output)\n",
    "\n",
    "#Combined model\n",
    "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
    "    gen_img = gen_model(lr_ip)\n",
    "    \n",
    "    gen_features = vgg(gen_img)\n",
    "    \n",
    "    disc_model.trainable = False\n",
    "    validity = disc_model(gen_img)\n",
    "    \n",
    "    return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load first n number of images (to train on a subset of all images)\n",
    "#For demo purposes, let us use 2500 images\n",
    "from skimage.transform import resize, rescale\n",
    "\n",
    "n=2500\n",
    "\n",
    "lr_list = os.listdir(\"Dataset/LR\")[:n]\n",
    "\n",
    "lr_images = []\n",
    "for img in tqdm(lr_list):\n",
    "    img_lr = cv2.imread(\"Dataset/LR/\" + img)\n",
    "    img_lr = cv2.cvtColor(img_lr, cv2.COLOR_BGR2RGB)\n",
    "    img_lr = cv2.resize(img_lr, (64, 64))\n",
    "    img_lr = img_lr.astype('float32') / 255.0    \n",
    "    lr_images.append(img_lr)   \n",
    "\n",
    "\n",
    "hr_list = os.listdir(\"Dataset/HR\")[:n]\n",
    "   \n",
    "hr_images = []\n",
    "for img in tqdm(hr_list):\n",
    "    img_hr = cv2.imread(\"Dataset/HR/\" + img)\n",
    "    img_hr = cv2.cvtColor(img_hr, cv2.COLOR_BGR2RGB)\n",
    "    img_hr = cv2.resize(img_hr, (256, 256))\n",
    "    img_hr = img_hr.astype('float32') / 255.0 \n",
    "    hr_images.append(img_hr)   \n",
    "\n",
    "lr_images = np.array(lr_images)\n",
    "hr_images = np.array(hr_images)\n",
    "\n",
    "#Sanity check, view few images\n",
    "import numpy as np\n",
    "\n",
    "for i in range(4):\n",
    "    a = np.random.randint(0,10)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('High Resolution Image', color = 'green', fontsize = 20)\n",
    "    plt.imshow(hr_images[a])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n",
    "    plt.imshow(lr_images[a])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split to training and test data\n",
    "lr_train, lr_test, hr_train, hr_test = train_test_split(lr_images, hr_images, \n",
    "                                                      test_size=0.2, random_state=42)\n",
    "\n",
    "hr_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])\n",
    "lr_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])\n",
    "\n",
    "lr_ip = Input(shape=lr_shape)\n",
    "print(lr_ip)\n",
    "hr_ip = Input(shape=hr_shape)\n",
    "print(hr_ip)\n",
    "\n",
    "\n",
    "generator = create_gen(lr_ip, num_res_block = 16)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = create_disc(hr_ip)\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "discriminator.summary()\n",
    "\n",
    "vgg = build_vgg((256,256,3))\n",
    "print(vgg.summary())\n",
    "vgg.trainable = False\n",
    "\n",
    "gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)\n",
    "\n",
    "\n",
    "gan_model.compile(loss=[\"binary_crossentropy\", \"mse\"], loss_weights=[1e-3, 1], optimizer=\"adam\")\n",
    "gan_model.summary()\n",
    "\n",
    "#Create a list of images for LR and HR in batches from which a batch of images\n",
    "#would be fetched during training. \n",
    "batch_size = 1  \n",
    "train_lr_batches = []\n",
    "train_hr_batches = []\n",
    "for it in range(int(hr_train.shape[0] / batch_size)):\n",
    "    start_idx = it * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    train_hr_batches.append(hr_train[start_idx:end_idx])\n",
    "    train_lr_batches.append(lr_train[start_idx:end_idx])\n",
    "    \n",
    "    \n",
    "epochs = 20\n",
    "#Enumerate training over epochs\n",
    "for e in range(epochs):\n",
    "    \n",
    "    fake_label = np.zeros((batch_size, 1)) # Assign a label of 0 to all fake (generated images)\n",
    "    real_label = np.ones((batch_size,1)) # Assign a label of 1 to all real images.\n",
    "    \n",
    "    #Create empty lists to populate gen and disc losses. \n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    #Enumerate training over batches. \n",
    "    for b in tqdm(range(len(train_hr_batches))):\n",
    "        lr_imgs = train_lr_batches[b] #Fetch a batch of LR images for training\n",
    "        hr_imgs = train_hr_batches[b] #Fetch a batch of HR images for training\n",
    "        \n",
    "        fake_imgs = generator.predict_on_batch(lr_imgs) #Fake images\n",
    "        \n",
    "        #First, train the discriminator on fake and real HR images. \n",
    "        discriminator.trainable = True\n",
    "        d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
    "        d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
    "        \n",
    "        #Now, train the generator by fixing discriminator as non-trainable\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        #Average the discriminator loss, just for reporting purposes. \n",
    "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real) \n",
    "        \n",
    "        #Extract VGG features, to be used towards calculating loss\n",
    "        image_features = vgg.predict(hr_imgs)\n",
    "     \n",
    "        #Train the generator via GAN. \n",
    "        #Remember that we have 2 losses, adversarial loss and content (VGG) loss\n",
    "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
    "        \n",
    "        #Save losses to a list so we can average and report. \n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_loss)\n",
    "        \n",
    "    #Convert the list of losses to an array to make it easy to average    \n",
    "    g_losses = np.array(g_losses)\n",
    "    d_losses = np.array(d_losses)\n",
    "    \n",
    "    #Calculate the average losses for generator and discriminator\n",
    "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
    "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
    "    \n",
    "    #Report the progress during training. \n",
    "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
    "\n",
    "    if (e+1) % 10 == 0: #Change the frequency for model saving, if needed\n",
    "        #Save the generator after every n epochs (Usually 10 epochs)\n",
    "        generator.save(\"gen_e_\"+ str(e+1) +\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To display an example of the SRGAN model - perform super resolution using saved generator model\n",
    "from keras.models import load_model\n",
    "from numpy.random import randint\n",
    "\n",
    "generator = load_model('gen_e_5.h5', compile=False)\n",
    "\n",
    "\n",
    "[X1, X2] = [lr_test, hr_test]\n",
    "# select random example\n",
    "ix = randint(0, len(X1), 1)\n",
    "src_image, tar_image = X1[ix], X2[ix]\n",
    "\n",
    "# generate image from source\n",
    "gen_image = generator.predict(src_image)\n",
    "\n",
    "\n",
    "# plot all three images\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('LR Image')\n",
    "plt.imshow(src_image[0,:,:,:])\n",
    "plt.subplot(232)\n",
    "plt.title('Superresolution')\n",
    "plt.imshow(gen_image[0,:,:,:])\n",
    "plt.subplot(233)\n",
    "plt.title('Orig. HR image')\n",
    "plt.imshow(tar_image[0,:,:,:])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
